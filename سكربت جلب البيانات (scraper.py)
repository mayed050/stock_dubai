import requests
from bs4 import BeautifulSoup
import json
import datetime
import time
import random
from fake_useragent import UserAgent

class StockScraper:
    def __init__(self):
        self.ua = UserAgent()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': self.ua.random,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        
    def get_dubai_market_data(self):
        """جلب بيانات سوق دبي المالي"""
        url = "https://marketwatch.dfm.ae/"
        
        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # البحث عن بيانات الأسهم
            stocks_data = {
                'DEWA': {'price': None, 'change': None},
                'SALIK': {'price': None, 'change': None},
                'TALABAT': {'price': None, 'change': None}
            }
            
            # البحث في الصفحة عن بيانات كل سهم
            for stock in stocks_data.keys():
                # البحث عن السهم في القائمة
                stock_element = soup.find('span', string=lambda text: text and stock in text)
                if stock_element:
                    parent = stock_element.parent
                    price_element = parent.find('span', class_=lambda x: x and any(char.isdigit() for char in x))
                    if price_element:
                        price_text = price_element.get_text().strip()
                        stocks_data[stock]['price'] = float(price_text.split('(')[0])
                        
                        change_element = parent.find('span', class_=lambda x: x and ('+' in x or '-' in x))
                        if change_element:
                            change_text = change_element.get_text().strip()
                            stocks_data[stock]['change'] = change_text
            
            # بيانات السوق العامة
            market_data = {
                'index': None,
                'change': None,
                'volume': None,
                'value': None
            }
            
            index_element = soup.find('span', string=lambda text: text and 'dfmgi' in text.lower())
            if index_element:
                parent_text = index_element.parent.get_text()
                # استخراج القيم باستخدام regex
                import re
                index_match = re.search(r'(\d+\.\d+)', parent_text)
                if index_match:
                    market_data['index'] = float(index_match.group(1))
                
                change_match = re.search(r'\(([^)]+)\)', parent_text)
                if change_match:
                    market_data['change'] = change_match.group(1)
            
            return {
                'dubai_market': market_data,
                'stocks': stocks_data,
                'timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"Error fetching Dubai market data: {e}")
            return None
    
    def get_abu_dhabi_market_data(self):
        """جلب بيانات سوق أبوظبي المالي"""
        url = "https://www.adx.ae/"
        
        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # بيانات NMDC Energy
            nmdc_data = {'price': None, 'change': None}
            
            # البحث عن NMDC في الصفحة
            nmdc_element = soup.find('span', string=lambda text: text and 'NMDCENR' in text)
            if nmdc_element:
                parent = nmdc_element.parent
                price_element = parent.find('span', class_=lambda x: x and any(char.isdigit() for char in x))
                if price_element:
                    price_text = price_element.get_text().strip()
                    nmdc_data['price'] = float(price_text.split('(')[0])
                    
                    change_element = parent.find('span', class_=lambda x: x and ('+' in x or '-' in x))
                    if change_element:
                        change_text = change_element.get_text().strip()
                        nmdc_data['change'] = change_text
            
            # بيانات السوق العامة
            market_data = {
                'fadgi': None,
                'fadgi_change': None,
                'fadx15': None,
                'fadx15_change': None
            }
            
            # البحث عن مؤشرات السوق
            indices = soup.find_all('span', string=lambda text: text and 'FADGI' in text)
            for index in indices:
                parent_text = index.parent.get_text()
                if 'FADGI' in parent_text:
                    import re
                    index_match = re.search(r'(\d+\.\d+)', parent_text)
                    if index_match:
                        market_data['fadgi'] = float(index_match.group(1))
                    
                    change_match = re.search(r'\(([^)]+)\)', parent_text)
                    if change_match:
                        market_data['fadgi_change'] = change_match.group(1)
            
            return {
                'abu_dhabi_market': market_data,
                'nmdc_energy': nmdc_data,
                'timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"Error fetching Abu Dhabi market data: {e}")
            return None
    
    def get_all_data(self):
        """جلب جميع البيانات"""
        print("Starting data collection...")
        
        # إضافة تأخير عشوائي بين الطلبات
        time.sleep(random.uniform(1, 3))
        
        dubai_data = self.get_dubai_market_data()
        
        time.sleep(random.uniform(1, 3))
        
        abu_dhabi_data = self.get_abu_dhabi_market_data()
        
        combined_data = {
            'dubai_market': dubai_data['dubai_market'] if dubai_data else None,
            'abu_dhabi_market': abu_dhabi_data['abu_dhabi_market'] if abu_dhabi_data else None,
            'stocks': {
                'DEWA': dubai_data['stocks']['DEWA'] if dubai_data else None,
                'SALIK': dubai_data['stocks']['SALIK'] if dubai_data else None,
                'TALABAT': dubai_data['stocks']['TALABAT'] if dubai_data else None,
                'NMDC': abu_dhabi_data['nmdc_energy'] if abu_dhabi_data else None
            },
            'last_updated': datetime.datetime.now().isoformat()
        }
        
        return combined_data
    
    def save_data(self, data, filename='daily_data.json'):
        """حفظ البيانات في ملف JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"Data saved to {filename}")

if __name__ == "__main__":
    scraper = StockScraper()
    data = scraper.get_all_data()
    scraper.save_data(data)
